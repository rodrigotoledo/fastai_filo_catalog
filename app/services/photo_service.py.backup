import os
import shutil
from pathlib import Path
from fastapi import UploadFile, HTTPException
from sqlalchemy.orm import Session
from app.models.photo import Photo
import aiofiles
from app.services.ai_service import AIService
from typing import List, Dict
import httpx
import uuid
import logging

logger = logging.getLogger(__name__)

UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

class PhotoService:
    def __init__(self, db: Session):
        self.db = db

    async def save_photo(self, file: UploadFile, user_description: str = None) -> Photo:
        """
        Salva foto no banco + upload para Gemini File Search Store
        """
        # Validar tipo de arquivo
        if not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Only image files are allowed")

        # Gerar nome único para o arquivo
        file_extension = Path(file.filename).suffix
        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = UPLOAD_DIR / unique_filename

        # Salvar arquivo no disco
        try:
            content = await file.read()
            with open(file_path, "wb") as buffer:
                buffer.write(content)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Failed to save file: {str(e)}")

        # Reset file pointer for potential reuse
        await file.seek(0)

        # Criar registro no banco
        photo = Photo(
            filename=unique_filename,
            original_filename=file.filename,
            file_path=str(file_path),
            file_size=len(content),
            content_type=file.content_type,
            user_description=user_description or "Foto sem descrição"
        )

        self.db.add(photo)
        self.db.commit()
        self.db.refresh(photo)

        # Upload para Gemini File Search Store (se disponível)
        try:
            ai_service = AIService()

            # Criar descrição rica para busca semântica
            descricao = f"""
            Foto: {photo.original_filename}
            Descrição: {user_description or 'Foto sem descrição específica'}
            Tipo: {photo.content_type}
            Tamanho: {photo.file_size} bytes
            """

            # File Search Store não está disponível na versão atual do SDK
            # Por enquanto, apenas salvar localmente
            logger.info("File Search Store não disponível - foto salva apenas localmente")

        except Exception as e:
            print(f"WARNING: Não foi possível enviar para Gemini File Search Store: {str(e)}")

        return photo

    def search_similar_photos_by_text(self, query_text: str = None, limit: int = 10) -> Dict:
        """
        Busca fotos por texto nas descrições (versão simplificada sem File Search Store)
        """
        if not query_text:
            raise HTTPException(status_code=400, detail="Query text is required for search")

        # Busca simples: procurar fotos cuja descrição contenha o texto da busca
        query_lower = query_text.lower()

        # Buscar fotos que contenham o termo na descrição
        matching_photos = []
        all_photos = self.db.query(Photo).all()

        for photo in all_photos:
            if photo.user_description and query_lower in photo.user_description.lower():
                matching_photos.append({
                    "photo": photo,
                    "similarity_score": 1.0  # Score máximo para correspondências
                })

        # Se não encontrou correspondências exatas, buscar por palavras individuais
        if not matching_photos:
            for photo in all_photos:
                if photo.user_description:
                    desc_lower = photo.user_description.lower()
                    # Verificar se alguma palavra da query está na descrição
                    if any(word in desc_lower for word in query_lower.split()):
                        matching_photos.append({
                            "photo": photo,
                            "similarity_score": 0.9  # Score menor para palavras individuais
                        })

        # Ordenar por score e limitar resultados
        matching_photos.sort(key=lambda x: x["similarity_score"], reverse=True)
        matching_photos = matching_photos[:limit]

        return {
            "results": matching_photos,
            "total": len(matching_photos),
            "message": f"Encontradas {len(matching_photos)} fotos que correspondem à busca",
            "search_method": "text_search"
        }

    async def populate_photo(self, term: str, count: int = 1) -> List[Photo]:
        """
        Baixa múltiplas imagens do LoremFlickr e salva como fotos
        """
        if count < 1 or count > 10:
            raise HTTPException(status_code=400, detail="Count must be between 1 and 10")

        photos = []
        for i in range(count):
            print(f"DEBUG: Starting populate_photo {i+1}/{count} for term: {term}")

            # Validar e sanitizar o termo
            if not term or not term.strip():
                raise HTTPException(status_code=400, detail="Term cannot be empty")

            # Limpar e codificar o termo para URL
            import urllib.parse
            clean_term = term.strip()

            # Lista de termos bloqueados ou problemáticos
            blocked_terms = ['nude', 'naked', 'sex', 'porn', 'adult']
            if any(blocked.lower() in clean_term.lower() for blocked in blocked_terms):
                raise HTTPException(status_code=400, detail="Term contains inappropriate content")

            # Tentar LoremFlickr primeiro
            try:
                encoded_term = urllib.parse.quote(clean_term)
                url = f"https://loremflickr.com/640/480/{encoded_term}"

                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(url)
                    response.raise_for_status()

                    content_type = response.headers.get('content-type', '')
                    if not content_type.startswith('image/'):
                        raise HTTPException(status_code=500, detail=f"Invalid response type: {content_type}")

                    content = response.content
                    if len(content) < 1000:
                        raise HTTPException(status_code=500, detail="Downloaded content is too small")

                    actual_term = clean_term

            except Exception as e:
                print(f"DEBUG: LoremFlickr failed: {str(e)}, trying fallback...")

                # Fallback para imagens aleatórias
                try:
                    fallback_url = "https://picsum.photos/640/480"

                    async with httpx.AsyncClient(timeout=10.0) as client:
                        response = await client.get(fallback_url)
                        response.raise_for_status()

                        content_type = response.headers.get('content-type', '')
                        if not content_type.startswith('image/'):
                            raise HTTPException(status_code=500, detail=f"Invalid fallback response type: {content_type}")

                        content = response.content
                        if len(content) < 1000:
                            raise HTTPException(status_code=500, detail="Downloaded fallback content is too small")

                        # Ajustar o termo para indicar que foi fallback
                        actual_term = f"{clean_term} (random)"

                except Exception as fallback_e:
                    raise HTTPException(status_code=500, detail=f"Failed to download fallback image: {str(fallback_e)}")

            # Gerar nome único para o arquivo
            unique_filename = f"{uuid.uuid4()}.jpg"
            file_path = UPLOAD_DIR / unique_filename

            # Salvar arquivo no disco
            try:
                with open(file_path, "wb") as buffer:
                    buffer.write(content)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Failed to save file: {str(e)}")

            # Criar registro no banco
            photo = Photo(
                filename=unique_filename,
                original_filename=f"{actual_term}_{i+1}.jpg",
                file_path=str(file_path),
                file_size=len(content),
                content_type="image/jpeg",
                user_description=actual_term
            )

            self.db.add(photo)
            self.db.commit()
            self.db.refresh(photo)

            photos.append(photo)

        return photos

    def get_photos(self, page: int = 1, page_size: int = 12):
        """
        Busca fotos com paginação
        """
        offset = (page - 1) * page_size
        total = self.db.query(Photo).count()
        photos = self.db.query(Photo).order_by(Photo.uploaded_at.desc()).offset(offset).limit(page_size).all()

        return {
            "photos": photos,
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": (total + page_size - 1) // page_size
        }

    def get_photo(self, photo_id: int) -> Photo:
        """
        Busca uma foto específica por ID
        """
        return self.db.query(Photo).filter(Photo.id == photo_id).first()

    def get_processing_stats(self):
        """
        Retorna estatísticas de processamento
        """
        total_photos = self.db.query(Photo).count()
        processed_photos = self.db.query(Photo).filter(Photo.processed == True).count()
        unprocessed_photos = total_photos - processed_photos

        return {
            "total_photos": total_photos,
            "processed_photos": processed_photos,
            "unprocessed_photos": unprocessed_photos,
            "processing_percentage": round((processed_photos / total_photos * 100) if total_photos > 0 else 0, 2)
        }

    async def populate_photo(self, term: str, count: int = 1) -> List[Photo]:
        """
        Baixa múltiplas imagens do LoremFlickr e salva como fotos
        """
        if count < 1 or count > 10:
            raise HTTPException(status_code=400, detail="Count must be between 1 and 10")

        photos = []
        for i in range(count):
            print(f"DEBUG: Starting populate_photo {i+1}/{count} for term: {term}")

            # Validar e sanitizar o termo
            if not term or not term.strip():
                raise HTTPException(status_code=400, detail="Term cannot be empty")

            # Limpar e codificar o termo para URL
            import urllib.parse
            clean_term = term.strip()

            # Lista de termos bloqueados ou problemáticos
            blocked_terms = ['nude', 'naked', 'sex', 'porn', 'adult']
            if any(blocked.lower() in clean_term.lower() for blocked in blocked_terms):
                raise HTTPException(status_code=400, detail="Term contains inappropriate content")

            encoded_term = urllib.parse.quote(clean_term)

            # URL do LoremFlickr com parâmetro rand para evitar cache
            import time
            rand_param = int(time.time() * 1000) + i  # timestamp + índice para variar
            url = f"https://loremflickr.com/800/600/{encoded_term}?rand={rand_param}"

            print(f"DEBUG: URL gerada: {url}")

            # Fazer download da imagem
            async with httpx.AsyncClient(follow_redirects=True) as client:
                try:
                    response = await client.get(url)
                    response.raise_for_status()

                    # Verificar se a resposta é realmente uma imagem
                    content_type = response.headers.get('content-type', '')
                    if not content_type.startswith('image/'):
                        print(f"DEBUG: Invalid response type: {content_type}, trying fallback")
                        # Tentar novamente sem termo específico (imagem aleatória)
                        fallback_url = f"https://loremflickr.com/800/600?rand={rand_param}"
                        response = await client.get(fallback_url)
                        response.raise_for_status()

                        content_type = response.headers.get('content-type', '')
                        if not content_type.startswith('image/'):
                            raise HTTPException(status_code=500, detail=f"Invalid fallback response type: {content_type}")

                        content = response.content
                        if len(content) < 1000:
                            raise HTTPException(status_code=500, detail="Downloaded fallback content is too small")

                        # Ajustar o termo para indicar que foi fallback
                        actual_term = f"{clean_term} (random)"
                    else:
                        content = response.content
                        actual_term = clean_term

                        # Verificar se o conteúdo não está vazio
                        if len(content) < 1000:  # Imagens devem ter pelo menos 1KB
                            raise HTTPException(status_code=500, detail="Downloaded content is too small")

                except httpx.HTTPStatusError as e:
                    if e.response.status_code == 403:
                        # Tentar novamente sem termo específico (imagem aleatória)
                        print(f"DEBUG: Term '{clean_term}' blocked, trying random image")
                        fallback_url = f"https://loremflickr.com/800/600?rand={rand_param}"
                        try:
                            response = await client.get(fallback_url)
                            response.raise_for_status()

                            content_type = response.headers.get('content-type', '')
                            if not content_type.startswith('image/'):
                                raise HTTPException(status_code=500, detail=f"Invalid fallback response type: {content_type}")

                            content = response.content
                            if len(content) < 1000:
                                raise HTTPException(status_code=500, detail="Downloaded fallback content is too small")

                            # Ajustar o termo para indicar que foi fallback
                            actual_term = f"{clean_term} (random)"

                        except Exception as fallback_e:
                            raise HTTPException(status_code=500, detail=f"Failed to download fallback image: {str(fallback_e)}")
                    else:
                        raise HTTPException(status_code=500, detail=f"Failed to download image: {str(e)}")
                except Exception as e:
                    raise HTTPException(status_code=500, detail=f"Failed to download image: {str(e)}")

            # Gerar nome único para o arquivo
            unique_filename = f"{uuid.uuid4()}.jpg"
            file_path = UPLOAD_DIR / unique_filename

            # Salvar arquivo no disco
            try:
                with open(file_path, "wb") as buffer:
                    buffer.write(content)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Failed to save file: {str(e)}")

            # Criar registro no banco
            photo = Photo(
                filename=unique_filename,
                original_filename=f"{actual_term}_{i+1}.jpg",
                file_path=str(file_path),
                file_size=len(content),
                content_type="image/jpeg",
                user_description=actual_term
            )

            self.db.add(photo)
            self.db.commit()
            self.db.refresh(photo)

            photos.append(photo)

        # Ordenar por data de upload descendente (mais recentes primeiro)
        photos_sorted = sorted(photos, key=lambda p: p.uploaded_at, reverse=True)
        return photos_sorted

    def get_photo(self, photo_id: int):
        return self.db.query(Photo).filter(Photo.id == photo_id).first()

    def search_similar_photos(self, query_text: str = None, photo_id: int = None, limit: int = 10):
        """
        Busca fotos similares por texto ou por outra foto
        """
        ai_service = AIService()

        # Tentar busca no Gemini File Search Store primeiro
        if query_text and ai_service.store_id:
            try:
                gemini_results = ai_service.search_files_in_store(query_text, max_results=limit)
                if gemini_results:
                    # Buscar fotos no banco pelos file_ids
                    file_ids = [result['file_id'] for result in gemini_results]
                    photos = self.db.query(Photo).filter(Photo.gemini_file_id.in_(file_ids)).all()

                    # Criar mapa de file_id -> foto
                    photo_map = {photo.gemini_file_id: photo for photo in photos}

                    # Montar resultado
                    results = []
                    for gemini_result in gemini_results:
                        file_id = gemini_result['file_id']
                        if file_id in photo_map:
                            photo = photo_map[file_id]
                            results.append({
                                "photo": photo,
                                "similarity_score": gemini_result.get('relevance', 0)
                            })

                    if results:
                        return {
                            "results": results[:limit],
                            "total": len(results),
                            "message": f"Encontradas {len(results)} fotos via Gemini File Search",
                            "search_method": "gemini_file_search"
                        }
            except Exception as e:
                print(f"Erro na busca Gemini File Search: {str(e)}")
                # Continua para busca por embeddings

        # Fallback: busca por embeddings
        # Buscar todas as fotos processadas
        processed_photos = self.db.query(Photo).filter(
            Photo.processed == True,
            Photo.embedding.isnot(None)
        ).all()

        if not processed_photos:
            return {
                "results": [],
                "total": 0,
                "message": "Nenhuma foto processada encontrada",
                "search_method": "embedding_search"
            }

        # Preparar embeddings
        embeddings = [(photo.id, photo.embedding) for photo in processed_photos]

        # Buscar por texto ou por foto similar
        if query_text:
            # Primeiro: buscar fotos com correspondência exata na descrição (prioridade máxima)
            exact_matches = []
            if query_text:
                query_lower = query_text.lower()
                for photo in processed_photos:
                    if photo.user_description and query_lower in photo.user_description.lower():
                        exact_matches.append((photo.id, 1.0))  # Score máximo para correspondências exatas

            # Segundo: buscar fotos similares por texto nas descrições (fallback sem embeddings)
            similar_photos = []
            query_lower = query_text.lower()
            for photo in processed_photos:
                # Pular fotos que já têm correspondência exata
                if photo.id in [eid for eid, _ in exact_matches]:
                    continue
                # Buscar por similaridade de texto na descrição
                if photo.user_description and any(word.lower() in photo.user_description.lower() for word in query_text.split()):
                    # Score baseado no número de palavras coincidentes
                    matching_words = sum(1 for word in query_text.split() if word.lower() in photo.user_description.lower())
                    score = min(0.9, matching_words / len(query_text.split()))  # Score máximo 0.9 para não competir com exatas
                    similar_photos.append((photo.id, score))

            # Ordenar por score decrescente e limitar
            similar_photos.sort(key=lambda x: x[1], reverse=True)
            similar_photos = similar_photos[:limit * 2]  # Pegar mais para ter opções

            # Combinar: correspondências exatas primeiro, depois similares
            all_similar_photos = exact_matches + similar_photos
        elif photo_id:
            # Buscar foto de referência
            ref_photo = self.db.query(Photo).filter(Photo.id == photo_id).first()
            if not ref_photo or not ref_photo.embedding:
                raise HTTPException(status_code=404, detail="Foto de referência não encontrada ou não processada")

            similar_photos = ai_service.search_similar_images(ref_photo.embedding, embeddings, limit)
        else:
            raise HTTPException(status_code=400, detail="Deve fornecer query_text ou photo_id")

        # Buscar fotos completas pelos IDs
        photo_ids = [photo_id for photo_id, _ in similar_photos]
        photos = self.db.query(Photo).filter(Photo.id.in_(photo_ids)).order_by(Photo.uploaded_at.desc()).all()

        # Criar mapa de ID -> foto
        photo_map = {photo.id: photo for photo in photos}

        # Montar resultado com scores
        results = []
        for photo_id, score in all_similar_photos:
            if photo_id in photo_map:
                photo = photo_map[photo_id]
                results.append({
                    "photo": photo,
                    "similarity_score": score
                })

        # Reordenar por score (já está ordenado, mas garantir)
        results.sort(key=lambda x: x["similarity_score"], reverse=True)
        results = results[:limit]

        return {
            "results": results,
            "total": len(results),
            "message": f"Encontradas {len(results)} fotos via busca por embeddings",
            "search_method": "embedding_search"
        }

    def get_processing_stats(self):
        """
        Retorna estatísticas de processamento
        """
        total_photos = self.db.query(Photo).count()
        processed_photos = self.db.query(Photo).filter(Photo.processed == True).count()
        unprocessed_photos = total_photos - processed_photos

        return {
            "total_photos": total_photos,
            "processed_photos": processed_photos,
            "unprocessed_photos": unprocessed_photos,
            "processing_percentage": round((processed_photos / total_photos * 100) if total_photos > 0 else 0, 2)
        }

    def get_photo(self, photo_id: int) -> Photo:
        """
        Busca uma foto específica por ID
        """
        return self.db.query(Photo).filter(Photo.id == photo_id).first()

    def get_photos(self, page: int = 1, page_size: int = 12) -> Dict:
        """
        Busca fotos com paginação
        """
        offset = (page - 1) * page_size
        photos = self.db.query(Photo).offset(offset).limit(page_size).all()
        total_photos = self.db.query(Photo).count()
        total_pages = (total_photos + page_size - 1) // page_size

        return {
            "photos": photos,
            "total": total_photos,
            "page": page,
            "page_size": page_size,
            "total_pages": total_pages
        }
        return {
            "photos": photos,
    def get_photos(self, page: int = 1, page_size: int = 12) -> Dict:
        """
        Busca fotos com paginação
        """
        offset = (page - 1) * page_size
        photos_query = self.db.query(Photo).offset(offset).limit(page_size).all()
        total_photos = self.db.query(Photo).count()
        total_pages = (total_photos + page_size - 1) // page_size
        
        # Converter objetos Photo para dicionários serializáveis
        photos_data = []
        for photo in photos_query:
            photos_data.append({
                "id": photo.id,
                "filename": photo.filename,
                "original_filename": photo.original_filename,
                "file_path": photo.file_path,
                "file_size": photo.file_size,
                "content_type": photo.content_type,
                "uploaded_at": photo.uploaded_at,
                "processed": photo.processed,
                "description": photo.description,
                "user_description": photo.user_description
            })

        return {
            "photos": photos_data,
            "total": total_photos,
            "page": page,
            "page_size": page_size,
            "total_pages": total_pages,
            "has_next": page < total_pages,
            "has_prev": page > 1
        }
